{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Using_Optimizers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9a0f55f7bbac47c689cff9c4139f9848":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f290f3a8266c443ea7d2de3a352ef09c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7f497ad93b08463282c6ac308a12f3f2","IPY_MODEL_506d4563715942b482daa3c59c447e94"]}},"f290f3a8266c443ea7d2de3a352ef09c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f497ad93b08463282c6ac308a12f3f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6a036239cb234c7b968d20f727eb4d99","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2889536cdbce40e2a11755d79ceab12a"}},"506d4563715942b482daa3c59c447e94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_08a254835acf43ef90c825c3e2b9611c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 26427392/? [00:20&lt;00:00, 3369101.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09923aa970a2439eafa144cbaa9405a5"}},"6a036239cb234c7b968d20f727eb4d99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2889536cdbce40e2a11755d79ceab12a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08a254835acf43ef90c825c3e2b9611c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"09923aa970a2439eafa144cbaa9405a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d958ae025580467f8888ec82cfecd3d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3e1d55f219f4414eadb3bcc2e1791355","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6e445b9c47674e17ad1e017942699b88","IPY_MODEL_2d913ad4328d4457a94ce4145c5e60fc"]}},"3e1d55f219f4414eadb3bcc2e1791355":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e445b9c47674e17ad1e017942699b88":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0819c9f6a210432890c4ace3274b69af","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de8e4ffdfcd6476396e904211af49ce7"}},"2d913ad4328d4457a94ce4145c5e60fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_30a29fdbfbcf409eb6fb08a0ecc87ca1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:14&lt;00:00, 56755.01it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad80cbe9ba5348ccab725dae26a0c58d"}},"0819c9f6a210432890c4ace3274b69af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"de8e4ffdfcd6476396e904211af49ce7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30a29fdbfbcf409eb6fb08a0ecc87ca1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ad80cbe9ba5348ccab725dae26a0c58d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe600a1b38614121b79c0b4baca2cc7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c2c6b6c93144622bfd0475c8df04093","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d2090828285c4962a95851f063372c78","IPY_MODEL_d60e95d43e0245768dd454a68e178098"]}},"2c2c6b6c93144622bfd0475c8df04093":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d2090828285c4962a95851f063372c78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_61bbcbd0e95f46efa2222649e94e7772","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c88f50ac7d464e93a2441e23427d9055"}},"d60e95d43e0245768dd454a68e178098":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_59253bbc140349d6a4b0fe8e0a91535a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4423680/? [00:13&lt;00:00, 1067408.30it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79d69bc3d44f40d29a1079d3d5c5a95b"}},"61bbcbd0e95f46efa2222649e94e7772":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c88f50ac7d464e93a2441e23427d9055":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59253bbc140349d6a4b0fe8e0a91535a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"79d69bc3d44f40d29a1079d3d5c5a95b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee7c89aa9eae4b669a520b8a71d4fcb6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4fb41202a4f44b6db6ee23c6322e6ff0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_00e8b9ac8beb4f63831923c235d724ea","IPY_MODEL_ad2284ab50fc4e0b85535ffb16118788"]}},"4fb41202a4f44b6db6ee23c6322e6ff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00e8b9ac8beb4f63831923c235d724ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9e91ff4083a047e181f95820a8ba39b0","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba4627a689654be2b997a4988f99cd2f"}},"ad2284ab50fc4e0b85535ffb16118788":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d66ea04483bc46c1a45f5708c6371c37","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/5148 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_52fb5a009d6a405b858205130ef43cdc"}},"9e91ff4083a047e181f95820a8ba39b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ba4627a689654be2b997a4988f99cd2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d66ea04483bc46c1a45f5708c6371c37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"52fb5a009d6a405b858205130ef43cdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"HBehvqZ8znsy","colab_type":"text"},"source":["# Using optimizers"]},{"cell_type":"code","metadata":{"id":"bCdIqY0tKbvS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593804831296,"user_tz":240,"elapsed":4656,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}}},"source":["# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n","import torch\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","import numpy as np\n","np.random.seed(0)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PCJzXv0OK1Bs","colab":{"base_uri":"https://localhost:8080/","height":367,"referenced_widgets":["9a0f55f7bbac47c689cff9c4139f9848","f290f3a8266c443ea7d2de3a352ef09c","7f497ad93b08463282c6ac308a12f3f2","506d4563715942b482daa3c59c447e94","6a036239cb234c7b968d20f727eb4d99","2889536cdbce40e2a11755d79ceab12a","08a254835acf43ef90c825c3e2b9611c","09923aa970a2439eafa144cbaa9405a5","d958ae025580467f8888ec82cfecd3d6","3e1d55f219f4414eadb3bcc2e1791355","6e445b9c47674e17ad1e017942699b88","2d913ad4328d4457a94ce4145c5e60fc","0819c9f6a210432890c4ace3274b69af","de8e4ffdfcd6476396e904211af49ce7","30a29fdbfbcf409eb6fb08a0ecc87ca1","ad80cbe9ba5348ccab725dae26a0c58d","fe600a1b38614121b79c0b4baca2cc7a","2c2c6b6c93144622bfd0475c8df04093","d2090828285c4962a95851f063372c78","d60e95d43e0245768dd454a68e178098","61bbcbd0e95f46efa2222649e94e7772","c88f50ac7d464e93a2441e23427d9055","59253bbc140349d6a4b0fe8e0a91535a","79d69bc3d44f40d29a1079d3d5c5a95b","ee7c89aa9eae4b669a520b8a71d4fcb6","4fb41202a4f44b6db6ee23c6322e6ff0","00e8b9ac8beb4f63831923c235d724ea","ad2284ab50fc4e0b85535ffb16118788","9e91ff4083a047e181f95820a8ba39b0","ba4627a689654be2b997a4988f99cd2f","d66ea04483bc46c1a45f5708c6371c37","52fb5a009d6a405b858205130ef43cdc"]},"executionInfo":{"status":"ok","timestamp":1593804841788,"user_tz":240,"elapsed":15143,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}},"outputId":"9da5a5b8-db12-4736-8df1-4e60eb6c6c7d"},"source":["from torchvision import datasets, transforms\n","import torch.nn.functional as F\n","from torch import nn\n","\n","mean, std = (0.5,), (0.5,)\n","\n","# Create a transform and normalise data\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize(mean, std)\n","                              ])\n","\n","# Download FMNIST training dataset and load training data\n","trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","# Download FMNIST test dataset and load test data\n","testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a0f55f7bbac47c689cff9c4139f9848","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d958ae025580467f8888ec82cfecd3d6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe600a1b38614121b79c0b4baca2cc7a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee7c89aa9eae4b669a520b8a71d4fcb6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"TZpZ12MrEDZI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593804841789,"user_tz":240,"elapsed":15141,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}}},"source":[""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"rqMqFbIVrbFH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593804841791,"user_tz":240,"elapsed":15140,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}}},"source":["class FMNIST(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.fc1 = nn.Linear(784, 128)\n","    self.fc2 = nn.Linear(128,64)\n","    self.fc3 = nn.Linear(64,10)\n","    \n","  def forward(self, x):\n","    x = x.view(x.shape[0], -1)\n","    \n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    x = F.log_softmax(x, dim=1)\n","    \n","    return x\n","    \n","#model = FMNIST()   "],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"m68OeMRdEF0X","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8c0QgxCF3fD-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593804842121,"user_tz":240,"elapsed":15467,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}}},"source":["model = nn.Sequential(nn.Linear(784, 128),\n","                      nn.ReLU(),\n","                      nn.Linear(128, 64),\n","                      nn.ReLU(),\n","                      nn.Linear(64, 10),\n","                      nn.LogSoftmax(dim=1))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjBut_7lhAc8","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p2ZAGFzFEQA_","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-iPQek2nz2yu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593804843420,"user_tz":240,"elapsed":1298,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}}},"source":["images, labels = next(iter(trainloader))\n","images = images.view(images.shape[0], -1)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMnVwV-CERd_","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"roihp-kN0Jw5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593804846146,"user_tz":240,"elapsed":782,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}}},"source":["from torch import optim\n","\n","criterion = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","# lr is the learning rate"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvbHIyPSEUPh","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtP3nCEQEUMH","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwcPkxQwEfYX","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Nf2WdmP5Gst","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"status":"ok","timestamp":1593804849022,"user_tz":240,"elapsed":2049,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}},"outputId":"8314fd13-0581-4047-edcc-0beecac9140d"},"source":["output = model(images)\n","loss = criterion(output, labels)\n","loss.backward()\n","print('Initial weights : ',model[0].weight)\n","print('Initial weights gradient : ',model[0].weight.grad)\n","        "],"execution_count":7,"outputs":[{"output_type":"stream","text":["Initial weights :  Parameter containing:\n","tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n","        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n","        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n","        ...,\n","        [ 0.0018, -0.0295,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n","        [-0.0233, -0.0220, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n","        [ 0.0309,  0.0066,  0.0125,  ...,  0.0286,  0.0350, -0.0105]],\n","       requires_grad=True)\n","Initial weights gradient :  tensor([[-0.0004, -0.0004, -0.0004,  ..., -0.0007, -0.0006, -0.0004],\n","        [ 0.0069,  0.0069,  0.0069,  ...,  0.0072,  0.0070,  0.0069],\n","        [-0.0015, -0.0015, -0.0015,  ..., -0.0016, -0.0015, -0.0015],\n","        ...,\n","        [ 0.0018,  0.0018,  0.0018,  ...,  0.0017,  0.0017,  0.0018],\n","        [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019],\n","        [ 0.0017,  0.0017,  0.0017,  ...,  0.0016,  0.0017,  0.0017]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"arwzAK-1EkEH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593804870725,"user_tz":240,"elapsed":1264,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}}},"source":["optimizer.step()\n","# updates weights ever so slightly"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"zD-u49yzEj6v","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PuGKi_nq6P0j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"status":"ok","timestamp":1593804876016,"user_tz":240,"elapsed":329,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}},"outputId":"e1f58425-e6fa-4f75-bd97-0f270f17ad4b"},"source":["print('Initial weights : ',model[0].weight)\n","print('Initial weights gradient : ',model[0].weight.grad)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Initial weights :  Parameter containing:\n","tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n","        [-0.0198, -0.0151, -0.0105,  ..., -0.0203, -0.0060, -0.0300],\n","        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n","        ...,\n","        [ 0.0018, -0.0296,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n","        [-0.0233, -0.0221, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n","        [ 0.0309,  0.0066,  0.0125,  ...,  0.0285,  0.0350, -0.0105]],\n","       requires_grad=True)\n","Initial weights gradient :  tensor([[-0.0004, -0.0004, -0.0004,  ..., -0.0007, -0.0006, -0.0004],\n","        [ 0.0069,  0.0069,  0.0069,  ...,  0.0072,  0.0070,  0.0069],\n","        [-0.0015, -0.0015, -0.0015,  ..., -0.0016, -0.0015, -0.0015],\n","        ...,\n","        [ 0.0018,  0.0018,  0.0018,  ...,  0.0017,  0.0017,  0.0018],\n","        [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019],\n","        [ 0.0017,  0.0017,  0.0017,  ...,  0.0016,  0.0017,  0.0017]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O8oIy5SkEpDn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593804921239,"user_tz":240,"elapsed":1283,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}}},"source":["optimizer.zero_grad()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnfpzGigEpAr","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EniqxHDwDa8d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"status":"ok","timestamp":1593804924124,"user_tz":240,"elapsed":632,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}},"outputId":"b534c6ef-c3a1-4e49-a68d-05e30bcc0531"},"source":["print('Initial weights : ',model[0].weight)\n","print('Initial weights gradient : ',model[0].weight.grad)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Initial weights :  Parameter containing:\n","tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n","        [-0.0198, -0.0151, -0.0105,  ..., -0.0203, -0.0060, -0.0300],\n","        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n","        ...,\n","        [ 0.0018, -0.0296,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n","        [-0.0233, -0.0221, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n","        [ 0.0309,  0.0066,  0.0125,  ...,  0.0285,  0.0350, -0.0105]],\n","       requires_grad=True)\n","Initial weights gradient :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9DViAViGEwyr","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGZhQE3tDcqb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593805094881,"user_tz":240,"elapsed":8874,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}},"outputId":"05ed3bf1-4d52-455f-e0c6-4289df9bc158"},"source":["model = FMNIST()\n","criterion = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","num_epochs = 1 # changed from 3\n","\n","for i in range(num_epochs):\n","    cum_loss = 0 # want to see loss for each batch (iteration)\n","    batch_num = 0\n","\n","    for batch_num,(images, labels) in enumerate(trainloader,1):\n","        # indicated that the tuple (images,labels) belongs in batch_num, and decided to enumerate\n","        optimizer.zero_grad()\n","        output = model(images)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        cum_loss += loss.item()\n","        print(f'Batch : {batch_num}, Loss : {loss.item()}')\n","       \n","     \n","    print(f\"Training loss: {cum_loss/len(trainloader)}\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Batch : 1, Loss : 2.3273112773895264\n","Batch : 2, Loss : 2.293184280395508\n","Batch : 3, Loss : 2.3112661838531494\n","Batch : 4, Loss : 2.3118538856506348\n","Batch : 5, Loss : 2.2956676483154297\n","Batch : 6, Loss : 2.293297529220581\n","Batch : 7, Loss : 2.2968060970306396\n","Batch : 8, Loss : 2.270711660385132\n","Batch : 9, Loss : 2.2949740886688232\n","Batch : 10, Loss : 2.294889450073242\n","Batch : 11, Loss : 2.3100788593292236\n","Batch : 12, Loss : 2.2990283966064453\n","Batch : 13, Loss : 2.2964749336242676\n","Batch : 14, Loss : 2.2953503131866455\n","Batch : 15, Loss : 2.266622543334961\n","Batch : 16, Loss : 2.2846598625183105\n","Batch : 17, Loss : 2.2752439975738525\n","Batch : 18, Loss : 2.261687755584717\n","Batch : 19, Loss : 2.293064832687378\n","Batch : 20, Loss : 2.27963924407959\n","Batch : 21, Loss : 2.255924701690674\n","Batch : 22, Loss : 2.262437343597412\n","Batch : 23, Loss : 2.254652976989746\n","Batch : 24, Loss : 2.2678797245025635\n","Batch : 25, Loss : 2.2677180767059326\n","Batch : 26, Loss : 2.240208387374878\n","Batch : 27, Loss : 2.2844808101654053\n","Batch : 28, Loss : 2.252140522003174\n","Batch : 29, Loss : 2.2464029788970947\n","Batch : 30, Loss : 2.2496814727783203\n","Batch : 31, Loss : 2.255459785461426\n","Batch : 32, Loss : 2.251750946044922\n","Batch : 33, Loss : 2.2412374019622803\n","Batch : 34, Loss : 2.24233078956604\n","Batch : 35, Loss : 2.241304874420166\n","Batch : 36, Loss : 2.22330641746521\n","Batch : 37, Loss : 2.223787784576416\n","Batch : 38, Loss : 2.209261655807495\n","Batch : 39, Loss : 2.2302896976470947\n","Batch : 40, Loss : 2.230492115020752\n","Batch : 41, Loss : 2.2180726528167725\n","Batch : 42, Loss : 2.1971888542175293\n","Batch : 43, Loss : 2.2160685062408447\n","Batch : 44, Loss : 2.195664167404175\n","Batch : 45, Loss : 2.1957168579101562\n","Batch : 46, Loss : 2.1685268878936768\n","Batch : 47, Loss : 2.1984055042266846\n","Batch : 48, Loss : 2.1886703968048096\n","Batch : 49, Loss : 2.1618125438690186\n","Batch : 50, Loss : 2.185882329940796\n","Batch : 51, Loss : 2.1491315364837646\n","Batch : 52, Loss : 2.2138187885284424\n","Batch : 53, Loss : 2.1932499408721924\n","Batch : 54, Loss : 2.1595945358276367\n","Batch : 55, Loss : 2.180995464324951\n","Batch : 56, Loss : 2.175490379333496\n","Batch : 57, Loss : 2.1365103721618652\n","Batch : 58, Loss : 2.184014320373535\n","Batch : 59, Loss : 2.1547746658325195\n","Batch : 60, Loss : 2.152982234954834\n","Batch : 61, Loss : 2.1260910034179688\n","Batch : 62, Loss : 2.1149020195007324\n","Batch : 63, Loss : 2.1577627658843994\n","Batch : 64, Loss : 2.1421494483947754\n","Batch : 65, Loss : 2.1260251998901367\n","Batch : 66, Loss : 2.103114366531372\n","Batch : 67, Loss : 2.1399641036987305\n","Batch : 68, Loss : 2.103525161743164\n","Batch : 69, Loss : 2.141773223876953\n","Batch : 70, Loss : 2.143674850463867\n","Batch : 71, Loss : 2.0862879753112793\n","Batch : 72, Loss : 2.1038365364074707\n","Batch : 73, Loss : 2.1009528636932373\n","Batch : 74, Loss : 2.0716054439544678\n","Batch : 75, Loss : 2.0745627880096436\n","Batch : 76, Loss : 2.0910110473632812\n","Batch : 77, Loss : 2.0952603816986084\n","Batch : 78, Loss : 2.1163408756256104\n","Batch : 79, Loss : 2.1010358333587646\n","Batch : 80, Loss : 2.049614667892456\n","Batch : 81, Loss : 2.0651257038116455\n","Batch : 82, Loss : 2.0325684547424316\n","Batch : 83, Loss : 2.066399574279785\n","Batch : 84, Loss : 2.148289918899536\n","Batch : 85, Loss : 2.090207099914551\n","Batch : 86, Loss : 2.0443286895751953\n","Batch : 87, Loss : 2.052696943283081\n","Batch : 88, Loss : 2.026848077774048\n","Batch : 89, Loss : 2.0298914909362793\n","Batch : 90, Loss : 1.9688053131103516\n","Batch : 91, Loss : 2.0118086338043213\n","Batch : 92, Loss : 2.0836970806121826\n","Batch : 93, Loss : 2.010647773742676\n","Batch : 94, Loss : 1.9646961688995361\n","Batch : 95, Loss : 2.0492053031921387\n","Batch : 96, Loss : 1.956960916519165\n","Batch : 97, Loss : 1.9700779914855957\n","Batch : 98, Loss : 2.062608480453491\n","Batch : 99, Loss : 2.0435540676116943\n","Batch : 100, Loss : 1.955322027206421\n","Batch : 101, Loss : 2.0120468139648438\n","Batch : 102, Loss : 2.0084404945373535\n","Batch : 103, Loss : 1.9569792747497559\n","Batch : 104, Loss : 1.95603609085083\n","Batch : 105, Loss : 2.011204719543457\n","Batch : 106, Loss : 1.9950954914093018\n","Batch : 107, Loss : 1.9327149391174316\n","Batch : 108, Loss : 1.9467616081237793\n","Batch : 109, Loss : 1.9839894771575928\n","Batch : 110, Loss : 1.9502699375152588\n","Batch : 111, Loss : 1.927895426750183\n","Batch : 112, Loss : 1.8983616828918457\n","Batch : 113, Loss : 1.933594822883606\n","Batch : 114, Loss : 1.8573122024536133\n","Batch : 115, Loss : 1.8805265426635742\n","Batch : 116, Loss : 1.9451875686645508\n","Batch : 117, Loss : 1.9638506174087524\n","Batch : 118, Loss : 1.9023414850234985\n","Batch : 119, Loss : 1.9239108562469482\n","Batch : 120, Loss : 1.876333475112915\n","Batch : 121, Loss : 1.9231791496276855\n","Batch : 122, Loss : 1.8109217882156372\n","Batch : 123, Loss : 1.8424402475357056\n","Batch : 124, Loss : 1.910401463508606\n","Batch : 125, Loss : 1.8196182250976562\n","Batch : 126, Loss : 1.8708537817001343\n","Batch : 127, Loss : 1.8149341344833374\n","Batch : 128, Loss : 1.8522870540618896\n","Batch : 129, Loss : 1.8546721935272217\n","Batch : 130, Loss : 1.8076210021972656\n","Batch : 131, Loss : 1.922482967376709\n","Batch : 132, Loss : 1.7730592489242554\n","Batch : 133, Loss : 1.7794854640960693\n","Batch : 134, Loss : 1.8797295093536377\n","Batch : 135, Loss : 1.8297165632247925\n","Batch : 136, Loss : 1.7591612339019775\n","Batch : 137, Loss : 1.744276762008667\n","Batch : 138, Loss : 1.8070275783538818\n","Batch : 139, Loss : 1.7021253108978271\n","Batch : 140, Loss : 1.683829426765442\n","Batch : 141, Loss : 1.6387605667114258\n","Batch : 142, Loss : 1.7369858026504517\n","Batch : 143, Loss : 1.8070783615112305\n","Batch : 144, Loss : 1.7636535167694092\n","Batch : 145, Loss : 1.6998896598815918\n","Batch : 146, Loss : 1.7508701086044312\n","Batch : 147, Loss : 1.6857255697250366\n","Batch : 148, Loss : 1.6326251029968262\n","Batch : 149, Loss : 1.7607771158218384\n","Batch : 150, Loss : 1.7454885244369507\n","Batch : 151, Loss : 1.8114914894104004\n","Batch : 152, Loss : 1.8074281215667725\n","Batch : 153, Loss : 1.7459534406661987\n","Batch : 154, Loss : 1.618270754814148\n","Batch : 155, Loss : 1.6749898195266724\n","Batch : 156, Loss : 1.6277682781219482\n","Batch : 157, Loss : 1.5555505752563477\n","Batch : 158, Loss : 1.691530466079712\n","Batch : 159, Loss : 1.7107964754104614\n","Batch : 160, Loss : 1.65519380569458\n","Batch : 161, Loss : 1.596288800239563\n","Batch : 162, Loss : 1.654441475868225\n","Batch : 163, Loss : 1.6711535453796387\n","Batch : 164, Loss : 1.6572893857955933\n","Batch : 165, Loss : 1.6169490814208984\n","Batch : 166, Loss : 1.5714964866638184\n","Batch : 167, Loss : 1.5390191078186035\n","Batch : 168, Loss : 1.6447176933288574\n","Batch : 169, Loss : 1.5337716341018677\n","Batch : 170, Loss : 1.5362979173660278\n","Batch : 171, Loss : 1.5263605117797852\n","Batch : 172, Loss : 1.5534254312515259\n","Batch : 173, Loss : 1.5021554231643677\n","Batch : 174, Loss : 1.4736301898956299\n","Batch : 175, Loss : 1.558469533920288\n","Batch : 176, Loss : 1.4495301246643066\n","Batch : 177, Loss : 1.6550812721252441\n","Batch : 178, Loss : 1.5451719760894775\n","Batch : 179, Loss : 1.5022175312042236\n","Batch : 180, Loss : 1.4786447286605835\n","Batch : 181, Loss : 1.4384431838989258\n","Batch : 182, Loss : 1.4458521604537964\n","Batch : 183, Loss : 1.493657112121582\n","Batch : 184, Loss : 1.626538872718811\n","Batch : 185, Loss : 1.4937560558319092\n","Batch : 186, Loss : 1.5313236713409424\n","Batch : 187, Loss : 1.4495095014572144\n","Batch : 188, Loss : 1.5047180652618408\n","Batch : 189, Loss : 1.5340452194213867\n","Batch : 190, Loss : 1.5063273906707764\n","Batch : 191, Loss : 1.4235426187515259\n","Batch : 192, Loss : 1.4888721704483032\n","Batch : 193, Loss : 1.4857906103134155\n","Batch : 194, Loss : 1.4768179655075073\n","Batch : 195, Loss : 1.3505070209503174\n","Batch : 196, Loss : 1.454956293106079\n","Batch : 197, Loss : 1.3749918937683105\n","Batch : 198, Loss : 1.3060822486877441\n","Batch : 199, Loss : 1.3821561336517334\n","Batch : 200, Loss : 1.4029353857040405\n","Batch : 201, Loss : 1.4221261739730835\n","Batch : 202, Loss : 1.4988561868667603\n","Batch : 203, Loss : 1.4285995960235596\n","Batch : 204, Loss : 1.4050811529159546\n","Batch : 205, Loss : 1.2593430280685425\n","Batch : 206, Loss : 1.4864599704742432\n","Batch : 207, Loss : 1.4399892091751099\n","Batch : 208, Loss : 1.3082202672958374\n","Batch : 209, Loss : 1.3609769344329834\n","Batch : 210, Loss : 1.398714303970337\n","Batch : 211, Loss : 1.4033256769180298\n","Batch : 212, Loss : 1.1473619937896729\n","Batch : 213, Loss : 1.4561622142791748\n","Batch : 214, Loss : 1.2958130836486816\n","Batch : 215, Loss : 1.2703216075897217\n","Batch : 216, Loss : 1.3266582489013672\n","Batch : 217, Loss : 1.3298673629760742\n","Batch : 218, Loss : 1.370274543762207\n","Batch : 219, Loss : 1.371834397315979\n","Batch : 220, Loss : 1.145382285118103\n","Batch : 221, Loss : 1.3204445838928223\n","Batch : 222, Loss : 1.2740365266799927\n","Batch : 223, Loss : 1.3130650520324707\n","Batch : 224, Loss : 1.2673838138580322\n","Batch : 225, Loss : 1.2436294555664062\n","Batch : 226, Loss : 1.226189374923706\n","Batch : 227, Loss : 1.2443220615386963\n","Batch : 228, Loss : 1.3343572616577148\n","Batch : 229, Loss : 1.1850758790969849\n","Batch : 230, Loss : 1.3133429288864136\n","Batch : 231, Loss : 1.3184876441955566\n","Batch : 232, Loss : 1.4127392768859863\n","Batch : 233, Loss : 1.3631834983825684\n","Batch : 234, Loss : 1.3164288997650146\n","Batch : 235, Loss : 1.2542227506637573\n","Batch : 236, Loss : 1.312017798423767\n","Batch : 237, Loss : 1.2638837099075317\n","Batch : 238, Loss : 1.2465497255325317\n","Batch : 239, Loss : 1.2897802591323853\n","Batch : 240, Loss : 1.2794123888015747\n","Batch : 241, Loss : 1.194608211517334\n","Batch : 242, Loss : 1.2498332262039185\n","Batch : 243, Loss : 1.1584416627883911\n","Batch : 244, Loss : 1.1943132877349854\n","Batch : 245, Loss : 1.215700626373291\n","Batch : 246, Loss : 1.2400009632110596\n","Batch : 247, Loss : 1.181870937347412\n","Batch : 248, Loss : 1.090733289718628\n","Batch : 249, Loss : 1.1674489974975586\n","Batch : 250, Loss : 1.1251928806304932\n","Batch : 251, Loss : 1.2300256490707397\n","Batch : 252, Loss : 1.0250967741012573\n","Batch : 253, Loss : 1.1399164199829102\n","Batch : 254, Loss : 1.1958332061767578\n","Batch : 255, Loss : 1.0432049036026\n","Batch : 256, Loss : 1.0621287822723389\n","Batch : 257, Loss : 1.199872374534607\n","Batch : 258, Loss : 1.0784401893615723\n","Batch : 259, Loss : 1.065917730331421\n","Batch : 260, Loss : 1.137269139289856\n","Batch : 261, Loss : 1.1109540462493896\n","Batch : 262, Loss : 1.1976875066757202\n","Batch : 263, Loss : 1.1297409534454346\n","Batch : 264, Loss : 1.1072371006011963\n","Batch : 265, Loss : 1.108964443206787\n","Batch : 266, Loss : 1.1546359062194824\n","Batch : 267, Loss : 1.186678409576416\n","Batch : 268, Loss : 1.1612699031829834\n","Batch : 269, Loss : 1.1416951417922974\n","Batch : 270, Loss : 1.1570370197296143\n","Batch : 271, Loss : 1.0596108436584473\n","Batch : 272, Loss : 1.2348864078521729\n","Batch : 273, Loss : 0.969756543636322\n","Batch : 274, Loss : 1.095859169960022\n","Batch : 275, Loss : 1.123828411102295\n","Batch : 276, Loss : 1.1918035745620728\n","Batch : 277, Loss : 1.06943678855896\n","Batch : 278, Loss : 1.1009647846221924\n","Batch : 279, Loss : 1.1134462356567383\n","Batch : 280, Loss : 1.1238844394683838\n","Batch : 281, Loss : 1.0628960132598877\n","Batch : 282, Loss : 1.0466152429580688\n","Batch : 283, Loss : 1.1142369508743286\n","Batch : 284, Loss : 1.015236735343933\n","Batch : 285, Loss : 1.0667567253112793\n","Batch : 286, Loss : 0.97877436876297\n","Batch : 287, Loss : 0.9881272912025452\n","Batch : 288, Loss : 1.1986292600631714\n","Batch : 289, Loss : 0.9701381921768188\n","Batch : 290, Loss : 1.0911551713943481\n","Batch : 291, Loss : 1.1162703037261963\n","Batch : 292, Loss : 1.1162831783294678\n","Batch : 293, Loss : 1.0415209531784058\n","Batch : 294, Loss : 0.9752519130706787\n","Batch : 295, Loss : 0.9725850820541382\n","Batch : 296, Loss : 1.0996335744857788\n","Batch : 297, Loss : 0.9933522939682007\n","Batch : 298, Loss : 1.0123423337936401\n","Batch : 299, Loss : 1.1646250486373901\n","Batch : 300, Loss : 0.9986432790756226\n","Batch : 301, Loss : 1.1009727716445923\n","Batch : 302, Loss : 1.0020027160644531\n","Batch : 303, Loss : 1.054235577583313\n","Batch : 304, Loss : 1.0283277034759521\n","Batch : 305, Loss : 0.9996098279953003\n","Batch : 306, Loss : 1.016979694366455\n","Batch : 307, Loss : 1.1654508113861084\n","Batch : 308, Loss : 0.9684611558914185\n","Batch : 309, Loss : 1.0222221612930298\n","Batch : 310, Loss : 1.0532379150390625\n","Batch : 311, Loss : 1.20604407787323\n","Batch : 312, Loss : 1.118337631225586\n","Batch : 313, Loss : 1.047707200050354\n","Batch : 314, Loss : 0.9664522409439087\n","Batch : 315, Loss : 0.8346861600875854\n","Batch : 316, Loss : 1.022657871246338\n","Batch : 317, Loss : 0.9046199917793274\n","Batch : 318, Loss : 1.0006773471832275\n","Batch : 319, Loss : 0.9734114408493042\n","Batch : 320, Loss : 1.0436794757843018\n","Batch : 321, Loss : 0.9620984792709351\n","Batch : 322, Loss : 0.8919892907142639\n","Batch : 323, Loss : 0.9384574294090271\n","Batch : 324, Loss : 1.1045818328857422\n","Batch : 325, Loss : 0.9861094355583191\n","Batch : 326, Loss : 0.9690812826156616\n","Batch : 327, Loss : 1.0247929096221924\n","Batch : 328, Loss : 0.9651251435279846\n","Batch : 329, Loss : 0.9823943376541138\n","Batch : 330, Loss : 0.9871729016304016\n","Batch : 331, Loss : 1.0445860624313354\n","Batch : 332, Loss : 0.8640490770339966\n","Batch : 333, Loss : 0.9529537558555603\n","Batch : 334, Loss : 0.957023561000824\n","Batch : 335, Loss : 1.0511647462844849\n","Batch : 336, Loss : 0.9836487174034119\n","Batch : 337, Loss : 0.925500750541687\n","Batch : 338, Loss : 1.0289306640625\n","Batch : 339, Loss : 1.071473479270935\n","Batch : 340, Loss : 0.9118155837059021\n","Batch : 341, Loss : 0.9953746199607849\n","Batch : 342, Loss : 0.9982456564903259\n","Batch : 343, Loss : 0.9288923144340515\n","Batch : 344, Loss : 1.1023085117340088\n","Batch : 345, Loss : 0.9437665343284607\n","Batch : 346, Loss : 1.0315576791763306\n","Batch : 347, Loss : 0.9392938613891602\n","Batch : 348, Loss : 1.0071433782577515\n","Batch : 349, Loss : 1.0192204713821411\n","Batch : 350, Loss : 1.0599911212921143\n","Batch : 351, Loss : 1.0648409128189087\n","Batch : 352, Loss : 0.8403050899505615\n","Batch : 353, Loss : 0.9934828281402588\n","Batch : 354, Loss : 0.8439376354217529\n","Batch : 355, Loss : 0.9413087964057922\n","Batch : 356, Loss : 0.8351961970329285\n","Batch : 357, Loss : 0.9771080017089844\n","Batch : 358, Loss : 0.9214141368865967\n","Batch : 359, Loss : 1.0070475339889526\n","Batch : 360, Loss : 0.7367008328437805\n","Batch : 361, Loss : 0.8449763655662537\n","Batch : 362, Loss : 0.9823431968688965\n","Batch : 363, Loss : 0.942173421382904\n","Batch : 364, Loss : 0.9092972874641418\n","Batch : 365, Loss : 1.0718679428100586\n","Batch : 366, Loss : 0.9499005675315857\n","Batch : 367, Loss : 0.9802026152610779\n","Batch : 368, Loss : 0.9553021192550659\n","Batch : 369, Loss : 0.9584802985191345\n","Batch : 370, Loss : 0.9101927280426025\n","Batch : 371, Loss : 0.9391774535179138\n","Batch : 372, Loss : 0.9224579334259033\n","Batch : 373, Loss : 1.1122301816940308\n","Batch : 374, Loss : 0.909572422504425\n","Batch : 375, Loss : 0.8718498349189758\n","Batch : 376, Loss : 0.8855853080749512\n","Batch : 377, Loss : 0.9148470759391785\n","Batch : 378, Loss : 0.9749129414558411\n","Batch : 379, Loss : 0.9812470078468323\n","Batch : 380, Loss : 0.9354065656661987\n","Batch : 381, Loss : 0.9981545209884644\n","Batch : 382, Loss : 0.8749372959136963\n","Batch : 383, Loss : 1.0383564233779907\n","Batch : 384, Loss : 0.8711703419685364\n","Batch : 385, Loss : 0.8778780102729797\n","Batch : 386, Loss : 0.8898893594741821\n","Batch : 387, Loss : 0.9857415556907654\n","Batch : 388, Loss : 0.9601755142211914\n","Batch : 389, Loss : 0.952974796295166\n","Batch : 390, Loss : 0.8925163149833679\n","Batch : 391, Loss : 0.9820722341537476\n","Batch : 392, Loss : 0.823897123336792\n","Batch : 393, Loss : 0.9577305912971497\n","Batch : 394, Loss : 0.9329569935798645\n","Batch : 395, Loss : 0.8806899785995483\n","Batch : 396, Loss : 0.9192200303077698\n","Batch : 397, Loss : 0.8574773073196411\n","Batch : 398, Loss : 0.940381646156311\n","Batch : 399, Loss : 0.8666719198226929\n","Batch : 400, Loss : 0.8554796576499939\n","Batch : 401, Loss : 0.8636574745178223\n","Batch : 402, Loss : 1.0034081935882568\n","Batch : 403, Loss : 0.7862417697906494\n","Batch : 404, Loss : 0.9210339784622192\n","Batch : 405, Loss : 0.9427768588066101\n","Batch : 406, Loss : 0.8704990148544312\n","Batch : 407, Loss : 0.9049021601676941\n","Batch : 408, Loss : 0.8576884865760803\n","Batch : 409, Loss : 0.7972546815872192\n","Batch : 410, Loss : 0.8513543009757996\n","Batch : 411, Loss : 0.7885669469833374\n","Batch : 412, Loss : 0.7859572172164917\n","Batch : 413, Loss : 0.8209636211395264\n","Batch : 414, Loss : 0.9094306826591492\n","Batch : 415, Loss : 0.8024451732635498\n","Batch : 416, Loss : 0.8691621422767639\n","Batch : 417, Loss : 0.7953078746795654\n","Batch : 418, Loss : 0.7965037822723389\n","Batch : 419, Loss : 0.8437090516090393\n","Batch : 420, Loss : 0.7596663236618042\n","Batch : 421, Loss : 0.9215366244316101\n","Batch : 422, Loss : 0.8011173009872437\n","Batch : 423, Loss : 0.7975947856903076\n","Batch : 424, Loss : 1.011278748512268\n","Batch : 425, Loss : 0.7971415519714355\n","Batch : 426, Loss : 0.994014322757721\n","Batch : 427, Loss : 0.8279838562011719\n","Batch : 428, Loss : 0.7668923735618591\n","Batch : 429, Loss : 0.8767347931861877\n","Batch : 430, Loss : 0.8824459910392761\n","Batch : 431, Loss : 0.7527402639389038\n","Batch : 432, Loss : 0.8126324415206909\n","Batch : 433, Loss : 0.8151461482048035\n","Batch : 434, Loss : 0.6073070764541626\n","Batch : 435, Loss : 0.8183319568634033\n","Batch : 436, Loss : 0.8008387684822083\n","Batch : 437, Loss : 0.7536025047302246\n","Batch : 438, Loss : 0.7344563603401184\n","Batch : 439, Loss : 0.7935022711753845\n","Batch : 440, Loss : 0.8040387630462646\n","Batch : 441, Loss : 0.805084228515625\n","Batch : 442, Loss : 0.8211209774017334\n","Batch : 443, Loss : 0.851611852645874\n","Batch : 444, Loss : 0.7371494174003601\n","Batch : 445, Loss : 0.6923137903213501\n","Batch : 446, Loss : 0.8441256284713745\n","Batch : 447, Loss : 0.7863665223121643\n","Batch : 448, Loss : 0.7977224588394165\n","Batch : 449, Loss : 0.8043187260627747\n","Batch : 450, Loss : 0.6792334914207458\n","Batch : 451, Loss : 0.8397293090820312\n","Batch : 452, Loss : 0.8697361350059509\n","Batch : 453, Loss : 0.771031379699707\n","Batch : 454, Loss : 0.8126727342605591\n","Batch : 455, Loss : 0.6270816922187805\n","Batch : 456, Loss : 0.8570786118507385\n","Batch : 457, Loss : 0.8426137566566467\n","Batch : 458, Loss : 0.8717027306556702\n","Batch : 459, Loss : 0.7391255497932434\n","Batch : 460, Loss : 0.7095186114311218\n","Batch : 461, Loss : 0.8423343896865845\n","Batch : 462, Loss : 0.647293210029602\n","Batch : 463, Loss : 0.8582838773727417\n","Batch : 464, Loss : 0.7238839864730835\n","Batch : 465, Loss : 0.763159453868866\n","Batch : 466, Loss : 0.8765307068824768\n","Batch : 467, Loss : 0.8412107229232788\n","Batch : 468, Loss : 0.7760308384895325\n","Batch : 469, Loss : 0.801580548286438\n","Batch : 470, Loss : 0.6863647699356079\n","Batch : 471, Loss : 0.847380518913269\n","Batch : 472, Loss : 0.9001515507698059\n","Batch : 473, Loss : 0.7945055961608887\n","Batch : 474, Loss : 0.9148766994476318\n","Batch : 475, Loss : 0.8279215693473816\n","Batch : 476, Loss : 0.715545654296875\n","Batch : 477, Loss : 0.7941469550132751\n","Batch : 478, Loss : 0.7993267178535461\n","Batch : 479, Loss : 0.8518547415733337\n","Batch : 480, Loss : 0.9756640791893005\n","Batch : 481, Loss : 0.7060246467590332\n","Batch : 482, Loss : 0.8207886815071106\n","Batch : 483, Loss : 0.8095157146453857\n","Batch : 484, Loss : 0.7697266340255737\n","Batch : 485, Loss : 0.7551530599594116\n","Batch : 486, Loss : 0.9006812572479248\n","Batch : 487, Loss : 0.7239062190055847\n","Batch : 488, Loss : 0.6565117239952087\n","Batch : 489, Loss : 0.8251330852508545\n","Batch : 490, Loss : 0.7854806780815125\n","Batch : 491, Loss : 0.7853289246559143\n","Batch : 492, Loss : 0.8286432027816772\n","Batch : 493, Loss : 0.6997423768043518\n","Batch : 494, Loss : 0.8673912882804871\n","Batch : 495, Loss : 0.7331609129905701\n","Batch : 496, Loss : 0.7486644983291626\n","Batch : 497, Loss : 0.9435229301452637\n","Batch : 498, Loss : 0.8769803643226624\n","Batch : 499, Loss : 0.7139676213264465\n","Batch : 500, Loss : 0.7867436408996582\n","Batch : 501, Loss : 0.8134595155715942\n","Batch : 502, Loss : 0.7951770424842834\n","Batch : 503, Loss : 0.8110448122024536\n","Batch : 504, Loss : 0.7855314016342163\n","Batch : 505, Loss : 0.5682211518287659\n","Batch : 506, Loss : 0.6269574165344238\n","Batch : 507, Loss : 0.8924821615219116\n","Batch : 508, Loss : 0.8022153973579407\n","Batch : 509, Loss : 0.8146772384643555\n","Batch : 510, Loss : 0.9540272355079651\n","Batch : 511, Loss : 1.0025633573532104\n","Batch : 512, Loss : 0.7074457406997681\n","Batch : 513, Loss : 0.9084705114364624\n","Batch : 514, Loss : 0.6224663257598877\n","Batch : 515, Loss : 0.838263988494873\n","Batch : 516, Loss : 0.822878897190094\n","Batch : 517, Loss : 0.7183208465576172\n","Batch : 518, Loss : 0.8823407292366028\n","Batch : 519, Loss : 0.8171542286872864\n","Batch : 520, Loss : 0.6724095344543457\n","Batch : 521, Loss : 0.8087441325187683\n","Batch : 522, Loss : 0.7228416800498962\n","Batch : 523, Loss : 0.9134390950202942\n","Batch : 524, Loss : 0.7112212777137756\n","Batch : 525, Loss : 0.8290937542915344\n","Batch : 526, Loss : 0.8415986895561218\n","Batch : 527, Loss : 0.7613735795021057\n","Batch : 528, Loss : 0.6551433801651001\n","Batch : 529, Loss : 0.8264554142951965\n","Batch : 530, Loss : 0.6280972361564636\n","Batch : 531, Loss : 0.8430714011192322\n","Batch : 532, Loss : 0.6474553346633911\n","Batch : 533, Loss : 0.6893210411071777\n","Batch : 534, Loss : 0.821264386177063\n","Batch : 535, Loss : 0.9134467840194702\n","Batch : 536, Loss : 1.0133849382400513\n","Batch : 537, Loss : 0.7656714916229248\n","Batch : 538, Loss : 0.7302986979484558\n","Batch : 539, Loss : 0.8212284445762634\n","Batch : 540, Loss : 0.8651365041732788\n","Batch : 541, Loss : 0.786227822303772\n","Batch : 542, Loss : 0.785592257976532\n","Batch : 543, Loss : 0.7764663696289062\n","Batch : 544, Loss : 0.7485920786857605\n","Batch : 545, Loss : 0.8592132329940796\n","Batch : 546, Loss : 0.7926102876663208\n","Batch : 547, Loss : 0.8510979413986206\n","Batch : 548, Loss : 0.7837698459625244\n","Batch : 549, Loss : 0.6937588453292847\n","Batch : 550, Loss : 0.6880781054496765\n","Batch : 551, Loss : 0.8868483304977417\n","Batch : 552, Loss : 0.6922813653945923\n","Batch : 553, Loss : 0.6026905179023743\n","Batch : 554, Loss : 0.774485170841217\n","Batch : 555, Loss : 0.6752322316169739\n","Batch : 556, Loss : 0.7375317811965942\n","Batch : 557, Loss : 0.6026614904403687\n","Batch : 558, Loss : 0.7372384071350098\n","Batch : 559, Loss : 0.6876019239425659\n","Batch : 560, Loss : 0.7780502438545227\n","Batch : 561, Loss : 0.8482325673103333\n","Batch : 562, Loss : 0.7800635695457458\n","Batch : 563, Loss : 0.8750580549240112\n","Batch : 564, Loss : 0.7080212235450745\n","Batch : 565, Loss : 0.9004774689674377\n","Batch : 566, Loss : 0.6859766840934753\n","Batch : 567, Loss : 0.6804128885269165\n","Batch : 568, Loss : 0.7694494128227234\n","Batch : 569, Loss : 0.8353064656257629\n","Batch : 570, Loss : 0.6751994490623474\n","Batch : 571, Loss : 0.7639976143836975\n","Batch : 572, Loss : 0.7527135014533997\n","Batch : 573, Loss : 0.7043352723121643\n","Batch : 574, Loss : 0.7168086171150208\n","Batch : 575, Loss : 0.7963311076164246\n","Batch : 576, Loss : 0.6002798080444336\n","Batch : 577, Loss : 0.8390539884567261\n","Batch : 578, Loss : 0.6267788410186768\n","Batch : 579, Loss : 0.6468489766120911\n","Batch : 580, Loss : 0.7508087158203125\n","Batch : 581, Loss : 0.5923113226890564\n","Batch : 582, Loss : 0.8506572246551514\n","Batch : 583, Loss : 0.6922179460525513\n","Batch : 584, Loss : 0.9217705130577087\n","Batch : 585, Loss : 0.6976444721221924\n","Batch : 586, Loss : 0.7630596160888672\n","Batch : 587, Loss : 0.6331158876419067\n","Batch : 588, Loss : 0.6442298293113708\n","Batch : 589, Loss : 0.8779240250587463\n","Batch : 590, Loss : 0.7617101669311523\n","Batch : 591, Loss : 0.7693935036659241\n","Batch : 592, Loss : 0.6655200719833374\n","Batch : 593, Loss : 0.7430157661437988\n","Batch : 594, Loss : 0.8678367733955383\n","Batch : 595, Loss : 0.6739276647567749\n","Batch : 596, Loss : 0.6620930433273315\n","Batch : 597, Loss : 0.691178560256958\n","Batch : 598, Loss : 0.6427633762359619\n","Batch : 599, Loss : 0.8190837502479553\n","Batch : 600, Loss : 0.6754717230796814\n","Batch : 601, Loss : 0.7521235942840576\n","Batch : 602, Loss : 0.9094693064689636\n","Batch : 603, Loss : 0.763068675994873\n","Batch : 604, Loss : 0.624161422252655\n","Batch : 605, Loss : 0.6525793075561523\n","Batch : 606, Loss : 0.671534538269043\n","Batch : 607, Loss : 0.7381928563117981\n","Batch : 608, Loss : 0.6565984487533569\n","Batch : 609, Loss : 0.8577747941017151\n","Batch : 610, Loss : 0.8465964198112488\n","Batch : 611, Loss : 0.8585233688354492\n","Batch : 612, Loss : 0.5577930212020874\n","Batch : 613, Loss : 0.7139304876327515\n","Batch : 614, Loss : 0.5755378007888794\n","Batch : 615, Loss : 0.7316449284553528\n","Batch : 616, Loss : 0.6866050362586975\n","Batch : 617, Loss : 0.9120911359786987\n","Batch : 618, Loss : 0.5945601463317871\n","Batch : 619, Loss : 0.7434573173522949\n","Batch : 620, Loss : 0.6608197093009949\n","Batch : 621, Loss : 0.8504917025566101\n","Batch : 622, Loss : 0.7011073231697083\n","Batch : 623, Loss : 0.6219558715820312\n","Batch : 624, Loss : 0.5793281197547913\n","Batch : 625, Loss : 0.6784802675247192\n","Batch : 626, Loss : 0.6754632592201233\n","Batch : 627, Loss : 0.6767398715019226\n","Batch : 628, Loss : 0.6994290947914124\n","Batch : 629, Loss : 0.7688103914260864\n","Batch : 630, Loss : 0.6751329302787781\n","Batch : 631, Loss : 0.5783237218856812\n","Batch : 632, Loss : 0.6229197978973389\n","Batch : 633, Loss : 0.5994378924369812\n","Batch : 634, Loss : 0.8890005946159363\n","Batch : 635, Loss : 0.737873911857605\n","Batch : 636, Loss : 0.9458001255989075\n","Batch : 637, Loss : 0.7082720994949341\n","Batch : 638, Loss : 0.6691229343414307\n","Batch : 639, Loss : 0.786156952381134\n","Batch : 640, Loss : 0.828480064868927\n","Batch : 641, Loss : 0.6616047024726868\n","Batch : 642, Loss : 0.7967668771743774\n","Batch : 643, Loss : 0.5121679902076721\n","Batch : 644, Loss : 0.7617524862289429\n","Batch : 645, Loss : 0.5821791887283325\n","Batch : 646, Loss : 0.7170842885971069\n","Batch : 647, Loss : 0.8153560757637024\n","Batch : 648, Loss : 0.6911876201629639\n","Batch : 649, Loss : 0.9210996627807617\n","Batch : 650, Loss : 0.6813796758651733\n","Batch : 651, Loss : 0.743331789970398\n","Batch : 652, Loss : 0.5179157853126526\n","Batch : 653, Loss : 0.731769859790802\n","Batch : 654, Loss : 0.7479686737060547\n","Batch : 655, Loss : 0.8091866374015808\n","Batch : 656, Loss : 0.7208265662193298\n","Batch : 657, Loss : 0.6284978985786438\n","Batch : 658, Loss : 0.603561282157898\n","Batch : 659, Loss : 0.6831122636795044\n","Batch : 660, Loss : 0.6508501172065735\n","Batch : 661, Loss : 0.8517587780952454\n","Batch : 662, Loss : 0.7086445093154907\n","Batch : 663, Loss : 0.7897759675979614\n","Batch : 664, Loss : 0.7139506936073303\n","Batch : 665, Loss : 0.6474398970603943\n","Batch : 666, Loss : 0.6890151500701904\n","Batch : 667, Loss : 0.7021759152412415\n","Batch : 668, Loss : 0.7152019739151001\n","Batch : 669, Loss : 0.6328343749046326\n","Batch : 670, Loss : 0.7883788347244263\n","Batch : 671, Loss : 0.6253615021705627\n","Batch : 672, Loss : 0.6547462940216064\n","Batch : 673, Loss : 0.6393873691558838\n","Batch : 674, Loss : 0.824077844619751\n","Batch : 675, Loss : 0.7207796573638916\n","Batch : 676, Loss : 0.7777431011199951\n","Batch : 677, Loss : 0.7428613305091858\n","Batch : 678, Loss : 0.7353305220603943\n","Batch : 679, Loss : 0.6703956127166748\n","Batch : 680, Loss : 0.7006704807281494\n","Batch : 681, Loss : 0.6558611989021301\n","Batch : 682, Loss : 0.706393837928772\n","Batch : 683, Loss : 0.8117828965187073\n","Batch : 684, Loss : 0.6920733451843262\n","Batch : 685, Loss : 0.7411490678787231\n","Batch : 686, Loss : 0.7310935258865356\n","Batch : 687, Loss : 0.8177554607391357\n","Batch : 688, Loss : 0.9082502722740173\n","Batch : 689, Loss : 0.9411776065826416\n","Batch : 690, Loss : 0.7364850044250488\n","Batch : 691, Loss : 0.8057397603988647\n","Batch : 692, Loss : 0.7336402535438538\n","Batch : 693, Loss : 0.687591552734375\n","Batch : 694, Loss : 0.7330647110939026\n","Batch : 695, Loss : 0.8087387084960938\n","Batch : 696, Loss : 0.7333458065986633\n","Batch : 697, Loss : 0.874630331993103\n","Batch : 698, Loss : 0.6052054762840271\n","Batch : 699, Loss : 0.851952850818634\n","Batch : 700, Loss : 0.6936704516410828\n","Batch : 701, Loss : 0.7707493901252747\n","Batch : 702, Loss : 0.6335064172744751\n","Batch : 703, Loss : 0.6772376894950867\n","Batch : 704, Loss : 0.708005964756012\n","Batch : 705, Loss : 0.7527475357055664\n","Batch : 706, Loss : 0.6065924763679504\n","Batch : 707, Loss : 0.6377304196357727\n","Batch : 708, Loss : 0.9024210572242737\n","Batch : 709, Loss : 0.8189218044281006\n","Batch : 710, Loss : 0.7374135851860046\n","Batch : 711, Loss : 0.6143263578414917\n","Batch : 712, Loss : 0.549786388874054\n","Batch : 713, Loss : 0.8488950133323669\n","Batch : 714, Loss : 0.8693808317184448\n","Batch : 715, Loss : 0.7122184634208679\n","Batch : 716, Loss : 0.7681177854537964\n","Batch : 717, Loss : 0.6535244584083557\n","Batch : 718, Loss : 0.6403049826622009\n","Batch : 719, Loss : 0.7696779370307922\n","Batch : 720, Loss : 0.6678258776664734\n","Batch : 721, Loss : 0.5137903690338135\n","Batch : 722, Loss : 0.8081005811691284\n","Batch : 723, Loss : 0.8084613084793091\n","Batch : 724, Loss : 0.7414114475250244\n","Batch : 725, Loss : 0.7732498645782471\n","Batch : 726, Loss : 0.663088321685791\n","Batch : 727, Loss : 0.7614527940750122\n","Batch : 728, Loss : 0.5605587959289551\n","Batch : 729, Loss : 0.6925652027130127\n","Batch : 730, Loss : 0.7569969296455383\n","Batch : 731, Loss : 0.6323879361152649\n","Batch : 732, Loss : 0.6035411953926086\n","Batch : 733, Loss : 0.5867923498153687\n","Batch : 734, Loss : 0.5775705575942993\n","Batch : 735, Loss : 0.7435668706893921\n","Batch : 736, Loss : 0.8573669195175171\n","Batch : 737, Loss : 0.8533199429512024\n","Batch : 738, Loss : 0.7395970821380615\n","Batch : 739, Loss : 0.5989600419998169\n","Batch : 740, Loss : 0.5641716718673706\n","Batch : 741, Loss : 0.7083388566970825\n","Batch : 742, Loss : 0.6836386919021606\n","Batch : 743, Loss : 0.6073178052902222\n","Batch : 744, Loss : 0.7224851250648499\n","Batch : 745, Loss : 0.5693384408950806\n","Batch : 746, Loss : 0.7741822004318237\n","Batch : 747, Loss : 0.6510053873062134\n","Batch : 748, Loss : 0.9085187315940857\n","Batch : 749, Loss : 0.5224825143814087\n","Batch : 750, Loss : 0.5554496645927429\n","Batch : 751, Loss : 0.7256033420562744\n","Batch : 752, Loss : 0.5776956081390381\n","Batch : 753, Loss : 0.6473878622055054\n","Batch : 754, Loss : 0.5489738583564758\n","Batch : 755, Loss : 0.7437782287597656\n","Batch : 756, Loss : 0.6338275074958801\n","Batch : 757, Loss : 0.6045593023300171\n","Batch : 758, Loss : 0.605405330657959\n","Batch : 759, Loss : 0.6632403135299683\n","Batch : 760, Loss : 0.532269299030304\n","Batch : 761, Loss : 0.6758881211280823\n","Batch : 762, Loss : 0.8258283138275146\n","Batch : 763, Loss : 0.5173543095588684\n","Batch : 764, Loss : 0.7496408820152283\n","Batch : 765, Loss : 0.6368176341056824\n","Batch : 766, Loss : 0.6189326047897339\n","Batch : 767, Loss : 0.5008601546287537\n","Batch : 768, Loss : 0.6405324339866638\n","Batch : 769, Loss : 0.724159300327301\n","Batch : 770, Loss : 0.7822675108909607\n","Batch : 771, Loss : 0.7779594659805298\n","Batch : 772, Loss : 0.5578423738479614\n","Batch : 773, Loss : 0.7197761535644531\n","Batch : 774, Loss : 0.634911060333252\n","Batch : 775, Loss : 0.5560474991798401\n","Batch : 776, Loss : 0.6276631951332092\n","Batch : 777, Loss : 0.4807799160480499\n","Batch : 778, Loss : 0.6103380918502808\n","Batch : 779, Loss : 0.5909135937690735\n","Batch : 780, Loss : 0.5853033661842346\n","Batch : 781, Loss : 0.586491584777832\n","Batch : 782, Loss : 0.6440344452857971\n","Batch : 783, Loss : 0.6111913919448853\n","Batch : 784, Loss : 0.6381796598434448\n","Batch : 785, Loss : 0.6048533320426941\n","Batch : 786, Loss : 0.7948800921440125\n","Batch : 787, Loss : 0.7359010577201843\n","Batch : 788, Loss : 0.7818343043327332\n","Batch : 789, Loss : 0.7830139994621277\n","Batch : 790, Loss : 0.4901583194732666\n","Batch : 791, Loss : 0.7393116354942322\n","Batch : 792, Loss : 0.6206238865852356\n","Batch : 793, Loss : 0.5093493461608887\n","Batch : 794, Loss : 0.6644991636276245\n","Batch : 795, Loss : 0.6052891612052917\n","Batch : 796, Loss : 0.48648542165756226\n","Batch : 797, Loss : 0.6263742446899414\n","Batch : 798, Loss : 0.7828538417816162\n","Batch : 799, Loss : 0.609865665435791\n","Batch : 800, Loss : 0.6975950598716736\n","Batch : 801, Loss : 0.5230947732925415\n","Batch : 802, Loss : 0.7484505772590637\n","Batch : 803, Loss : 0.5206252336502075\n","Batch : 804, Loss : 0.7293809056282043\n","Batch : 805, Loss : 0.7785860300064087\n","Batch : 806, Loss : 0.6438401937484741\n","Batch : 807, Loss : 0.8000273108482361\n","Batch : 808, Loss : 0.80913245677948\n","Batch : 809, Loss : 0.6372702717781067\n","Batch : 810, Loss : 0.6443787813186646\n","Batch : 811, Loss : 0.5922211408615112\n","Batch : 812, Loss : 0.6256951093673706\n","Batch : 813, Loss : 0.5687094330787659\n","Batch : 814, Loss : 0.7052818536758423\n","Batch : 815, Loss : 0.6688368916511536\n","Batch : 816, Loss : 0.5904249548912048\n","Batch : 817, Loss : 0.6995392441749573\n","Batch : 818, Loss : 0.6213527917861938\n","Batch : 819, Loss : 0.7425802946090698\n","Batch : 820, Loss : 0.48781347274780273\n","Batch : 821, Loss : 0.5921103954315186\n","Batch : 822, Loss : 0.70977783203125\n","Batch : 823, Loss : 0.5856882333755493\n","Batch : 824, Loss : 0.9057977795600891\n","Batch : 825, Loss : 0.49263259768486023\n","Batch : 826, Loss : 0.6405944228172302\n","Batch : 827, Loss : 0.4563542306423187\n","Batch : 828, Loss : 0.6861488819122314\n","Batch : 829, Loss : 0.861687183380127\n","Batch : 830, Loss : 0.654552161693573\n","Batch : 831, Loss : 0.4490295350551605\n","Batch : 832, Loss : 0.6908265948295593\n","Batch : 833, Loss : 0.5687650442123413\n","Batch : 834, Loss : 0.7361218929290771\n","Batch : 835, Loss : 0.6638311743736267\n","Batch : 836, Loss : 0.6115629076957703\n","Batch : 837, Loss : 0.7165715098381042\n","Batch : 838, Loss : 0.8055444955825806\n","Batch : 839, Loss : 0.6908993124961853\n","Batch : 840, Loss : 0.7548238635063171\n","Batch : 841, Loss : 0.6105538010597229\n","Batch : 842, Loss : 0.48838186264038086\n","Batch : 843, Loss : 0.6444941759109497\n","Batch : 844, Loss : 0.7483074069023132\n","Batch : 845, Loss : 0.613812267780304\n","Batch : 846, Loss : 0.6286163926124573\n","Batch : 847, Loss : 0.6471247673034668\n","Batch : 848, Loss : 0.7094141840934753\n","Batch : 849, Loss : 0.6184860467910767\n","Batch : 850, Loss : 0.8234072923660278\n","Batch : 851, Loss : 0.5967857837677002\n","Batch : 852, Loss : 0.7047364115715027\n","Batch : 853, Loss : 0.7172049283981323\n","Batch : 854, Loss : 0.579811155796051\n","Batch : 855, Loss : 0.794376015663147\n","Batch : 856, Loss : 0.7393946647644043\n","Batch : 857, Loss : 0.6136763095855713\n","Batch : 858, Loss : 0.6061059832572937\n","Batch : 859, Loss : 0.5656526684761047\n","Batch : 860, Loss : 0.6066430807113647\n","Batch : 861, Loss : 0.4662275016307831\n","Batch : 862, Loss : 0.6749910712242126\n","Batch : 863, Loss : 0.7102916836738586\n","Batch : 864, Loss : 0.5478457808494568\n","Batch : 865, Loss : 0.6534011363983154\n","Batch : 866, Loss : 0.6479743719100952\n","Batch : 867, Loss : 0.701245129108429\n","Batch : 868, Loss : 0.7903859615325928\n","Batch : 869, Loss : 0.5271766781806946\n","Batch : 870, Loss : 0.49753662943840027\n","Batch : 871, Loss : 0.5303327441215515\n","Batch : 872, Loss : 0.7028155326843262\n","Batch : 873, Loss : 0.5503045916557312\n","Batch : 874, Loss : 0.5853623747825623\n","Batch : 875, Loss : 0.8411470651626587\n","Batch : 876, Loss : 0.5865780115127563\n","Batch : 877, Loss : 0.6469948291778564\n","Batch : 878, Loss : 0.5588973760604858\n","Batch : 879, Loss : 0.49517881870269775\n","Batch : 880, Loss : 0.5952534675598145\n","Batch : 881, Loss : 0.6198689937591553\n","Batch : 882, Loss : 0.6277535557746887\n","Batch : 883, Loss : 0.9258029460906982\n","Batch : 884, Loss : 0.6464310884475708\n","Batch : 885, Loss : 0.6362239718437195\n","Batch : 886, Loss : 0.8353440165519714\n","Batch : 887, Loss : 0.7380416989326477\n","Batch : 888, Loss : 0.8363584876060486\n","Batch : 889, Loss : 0.5739362835884094\n","Batch : 890, Loss : 0.6972647309303284\n","Batch : 891, Loss : 0.6996551752090454\n","Batch : 892, Loss : 0.7093978524208069\n","Batch : 893, Loss : 0.7814003229141235\n","Batch : 894, Loss : 0.6296309232711792\n","Batch : 895, Loss : 0.5360816717147827\n","Batch : 896, Loss : 0.5018361806869507\n","Batch : 897, Loss : 0.6824226379394531\n","Batch : 898, Loss : 0.6909299492835999\n","Batch : 899, Loss : 0.6936240196228027\n","Batch : 900, Loss : 0.6948215961456299\n","Batch : 901, Loss : 0.48463132977485657\n","Batch : 902, Loss : 0.6193417310714722\n","Batch : 903, Loss : 0.5785410404205322\n","Batch : 904, Loss : 0.5526588559150696\n","Batch : 905, Loss : 0.5188390612602234\n","Batch : 906, Loss : 0.7890340685844421\n","Batch : 907, Loss : 0.6565383672714233\n","Batch : 908, Loss : 0.7198598384857178\n","Batch : 909, Loss : 0.5977882146835327\n","Batch : 910, Loss : 0.7209410667419434\n","Batch : 911, Loss : 0.68724125623703\n","Batch : 912, Loss : 0.6171932816505432\n","Batch : 913, Loss : 0.5216043591499329\n","Batch : 914, Loss : 0.6802864670753479\n","Batch : 915, Loss : 0.5904698967933655\n","Batch : 916, Loss : 0.4862450361251831\n","Batch : 917, Loss : 0.5816711187362671\n","Batch : 918, Loss : 0.601197361946106\n","Batch : 919, Loss : 0.7041201591491699\n","Batch : 920, Loss : 0.7075081467628479\n","Batch : 921, Loss : 0.5541336536407471\n","Batch : 922, Loss : 0.6058876514434814\n","Batch : 923, Loss : 0.5957156419754028\n","Batch : 924, Loss : 0.801189661026001\n","Batch : 925, Loss : 0.6127724647521973\n","Batch : 926, Loss : 0.698039174079895\n","Batch : 927, Loss : 0.48880115151405334\n","Batch : 928, Loss : 0.5607507228851318\n","Batch : 929, Loss : 0.46086233854293823\n","Batch : 930, Loss : 0.7303630113601685\n","Batch : 931, Loss : 0.6144897937774658\n","Batch : 932, Loss : 0.543839693069458\n","Batch : 933, Loss : 0.5324357748031616\n","Batch : 934, Loss : 0.7097559571266174\n","Batch : 935, Loss : 0.6100807189941406\n","Batch : 936, Loss : 0.4964297115802765\n","Batch : 937, Loss : 0.6757065653800964\n","Batch : 938, Loss : 0.7354549765586853\n","Training loss: 1.0541102207863509\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-OVDFUnzFGpr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593805161977,"user_tz":240,"elapsed":1277,"user":{"displayName":"Kellie Gadeken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggu6tgHDvaEbWKHpH33FlTePRPPx6PcGzyJI85X=s64","userId":"05109163810758256272"}},"outputId":"6986ead1-f736-48a7-d811-7c6ec46fbef6"},"source":["60000/64\n","\n","# 938 batches"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["937.5"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"hWf1SWuiFGmn","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OQ_QUMXLFGjr","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}